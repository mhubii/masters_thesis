\label{sec::8_co}
The communication with Heicub is implemented via yet another robot platform (YARP) \cite{metta2006yarp}, and is also part of the walking pattern generator libraries, as is shown in figure \ref{fig::8_folder}. 
\begin{figure}[h!]
	\begin{forest}
		for tree={
			font=\ttfamily,
			grow'=0,
			child anchor=west,
			parent anchor=south,
			anchor=west,
			calign=first,
			edge path={
				\noexpand\path [draw, \forestoption{edge}]
				(!u.south west) +(7.5pt,0) |- node[fill,inner sep=1.25pt] {} (.child anchor)\forestoption{edge label};
			},
			before typesetting nodes={
				if n=1
				{insert before={[,phantom]}}
				{}
			},
			fit=band,
			before computing xy={l=15pt},
		}
		[\href{https://github.com/mhubii/nmpc_pattern_generator}{\underline{nmpc\_pattern\_generator}}
		[\href{https://github.com/mhubii/nmpc_pattern_generator/tree/master/libs}{\underline{libs}}
		[\href{https://github.com/mhubii/nmpc_pattern_generator/tree/master/libs/io_module}{\underline{io\_module}}
		[\href{https://github.com/mhubii/nmpc_pattern_generator/tree/master/libs/io_module/include/io_module}{\underline{include/io\_module}}[reader.h][writer.h]]
		[configs.yaml][cam\_stereo.yaml]]
		]
		[\href{https://github.com/mhubii/nmpc_pattern_generator/tree/master/models}{\underline{models}}]
		[\href{https://github.com/mhubii/nmpc_pattern_generator/tree/master/sh}{\underline{sh}}]
		[\href{https://github.com/mhubii/nmpc_pattern_generator/tree/master/src}{\underline{src}}]
		]
	\end{forest}
	\caption{The libraries within the walking pattern generator, which are committed to the communication with Heicub. The code is freely available on GitHub at the provided \href{https://github.com/mhubii/nmpc_pattern_generator}{\underline{link}}. Install instruction can be found in the appendix \ref{sec::A_si}.}
	\label{fig::8_folder}
\end{figure}
With YARP \cite{metta2006yarp}, it is possible to directly interface the robot's motors, the cameras, and the force-torque sensors. Moreover, it enables the user to run multiple programs in parallel, which can then communicate with each other, which is of special importance for the control loop that was implemented within the scope of this thesis (see figure \ref{fig::8_yarp}).
\begin{figure}[h!]
	\hspace*{-1cm}
	\includegraphics[scale=.4]{chapters/06_implementation_of_the_walking_pattern_generator/img/yarp_diag.png}
	\caption{YARP is used to run multiple threads in parallel, each of which is indicated by the dashed boxes. It further enables the individual threads to communicate with each other via ports, which exchange YARP objects. It enables communication to the real robot as well as to a simulated version of it. The diagram demonstrates the types of data, which are being used, and the functions that convert them. Notice that this is an extended version of figure \ref{fig::7_cl}.}
	\label{fig::8_yarp}
\end{figure}
As was described in the previous section, one of these threads is committed to make decisions with a neural network, given RGBD images. This thread is depicted as the artificial agent thread in figure \ref{fig::8_yarp}, and it may also be replaced by a thread that communicates with a human user. The pattern generation thread performs the nonlinear model predictive control, given the velocity command of the artificial agent thread. Furthermore, there are two additional running threads that communicate with Heicub's motors. These threads are the read, and the write thread in figure \ref{fig::8_yarp}. The classes, which implement the communication to the robot, are located within the io\_module folder of figure \ref{fig::8_folder}. The \inlinecode{C++}{WriteJoints} class implements a \inlinecode{C++}{yarp::os::RateThread}, which is periodically being called, to accesses the motors, which are defined within the YAML configuration file, and it changes the motors' settings to position direct mode. Therefore, whatever is being written to the port that \inlinecode{C++}{WriteJoints} uses to communicate with the YARP network, and which is defined in the YAML configuration file, directly gets executed on the robot's motors. This communication to Heicub's motors corresponds to the very lowest part of figure \ref{fig::8_yarp}, where, as explain in section \ref{sec::6_pg}, the pattern generation uses the forward kinematics to generate joint angles $\bm{q}$, which are being written as \inlinecode{C++}{yarp::sig::Vector} to the \inlinecode{C++}{WriteJoints} rate thread. The reading of the robot's sensors is also implemented as part of the io\_module folder from figure \ref{fig::8_folder}. There are several classes, which implement \inlinecode{C++}{yarp::os::RateThread}s for different reading tasks. Among them are the \inlinecode{C++}{ReadJoints} class, which reads out the motor encoders to obtain the joint angles, the \inlinecode{C++}{ReadCameras} class, which reads out the cameras and pushes them as \inlinecode{C++}{yarp::sig::ImageOf<yarp::sig::PixelRgb>} onto the network (see figure \ref{fig::8_yarp}), as well as the \inlinecode{C++}{AppReader} class, and the \inlinecode{C++}{KeyReader} class, which handle the communication to the joystick app, and the terminal, respectively. Both, the \inlinecode{C++}{AppReader} class, and the \inlinecode{C++}{KeyReader} class, utilize NCurses to generate a user interface on the terminal, which is internally being trapped in a while loop until exit. They read out the input, which may originate from the joystick app, or the keyboard, and push them as the velocity commands onto the YARP network (see figure \ref{fig::8_yarp} left). The velocity commands, which are converted into an \inlinecode{C++}{Eigen::Vector3d} for the \inlinecode{C++}{NMPCGenerator::SetVelocityReference} method from section \ref{sec::62_id}, may alternatively also originate from a neural network, which is being presented in figure \ref{fig::8_yarp}. The \inlinecode{C++}{GenerateVelocityCommands} rate thread, which enables this feature, is implemented as part of the src folder in \ref{fig::8_folder}, as it only utilizes the provided libraries. It can be found at the provided \href{https://github.com/mhubii/nmpc_pattern_generator/blob/719fde0bb73925923de85cbf379c5523e075dfeb/src/behavioural_augmentation_real_robot_external_data.cpp#L108}{\underline{link}}. Its main task is to read in the images, which are constantly being pushed to the YARP network by \inlinecode{C++}{ReadCameras}, and to convert them into \inlinecode{C++}{cv::Mat} matrices, to perform the image processing on them, which includes the rectification, and the depth map extraction that are explained in section \ref{sec::3_ip}. It relies on the rectification matrices $\bm{R}_i$, and the projection matrices $\bm{P}_i$ that got explained in section \ref{sec::3_ip}, and that are stored with YAML files inside the io\_module folder of figure \ref{fig::8_folder}. They are highly dependent on the robot but do not change for Heicub over time, for why the future reader will be able to reuse them. The \inlinecode{C++}{GenerateVelocityCommands} class additionally stores a sequence of the processed images in the form of a \inlinecode{C++}{std::vector<torch::Tensor>}. Whenever a new image is read from the YARP network, the oldest image within the \inlinecode{C++}{std::vector<torch::Tensor>} is being deleted, and all other images are shifted up by one index, such that the newest image is available as the first entry. This vector of tensors is then being converted into a single tensor, by concatenating the individual tensors along the first dimension, which is, by definition of the long short-term memory units, required in PyTorch. The concatenated tensor is further being converted into a \inlinecode{C++}{std::vector<torch::jit::IValue>}, such that the JIT script, which defines the neural network that got trained in Python (see \ref{sec::712_id}), can forward it. The output is then obtained as a \inlinecode{C++}{torch::Tensor}, which is being written in the form of a \inlinecode{C++}{yarp::sig::Vector} to the YARP network, such that,  as explained above, the pattern generation can use it as input. This pipeline works equivalently on the real robot, as well as on the simulated version of it in Gazebo from section \ref{sec::5_he}, for which install instructions are provided in the appendix \ref{sec::A4_sm}. This pipeline finally enables one to run experiments on Heicub, and to evaluate the presented methods, which will be done in the following chapter.