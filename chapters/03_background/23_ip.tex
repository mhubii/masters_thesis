\subsection{Image Processing}
In the previous sections we have learned about two different approaches to train neural nets on solving certain tasks. Although we came to understand that the complexity of the task to be solved correlates strongly with the amount of data at hand, there exist domains from which it is undeniably easier to do so. To equip a neural net with some sort of prior knowledge by switching the domain may therefore not only be highly desirable but sometimes also needed if the amount or quality of data is not sufficient. One domain which is of special interest when it comes to interacting in a three dimensional environment is a domain that represents depth information. If there are any, it may sometimes be possible to extract this kind of prior knowledge from a depth camera. As for this work, we need to rely on stereo cameras and powerful algorithms that allow us to compute depth images in real time. As a requirement for the algorithm to work properly, it is important to calibrate the robot's cameras. Therefore, the next paragraph - Mono and Stereo Camera Calibration, will explain in detail why, and how to calibrate cameras.
\subsubsection{Mono and Stereo Camera Calibration}
asd
\\\\
The algorithm that helps us to do so, in terms of the extraction of weighted least squares disparity maps, will be presented in the following paragraph - Depth Map Extraction.
\subsubsection{Depth Map Extraction}
As already pointed out, the depth map is generated from stereo camera images by a technique called stereo block matching \cite{hamzah2010sum}. This method works best for edge filtered images, as will become clear soon. To obtain edge filtered images $\bm{E}$, the stereo RGB images are first converted into grayscale $\bm{G}$, which are then convolved with the Sobel kernel $\bm{S}_x$ along the horizontal axis \cite{sobel2014an} (equation \ref{eq::323_sobel_conv}, figure \ref{fig::323_image_preprocessing}). 
\begin{align}
	\bm{E} = \bm{S}_x*\bm{G}
	\label{eq::323_sobel_conv}
\end{align}
\begin{figure}[h]
	\centering
	\includegraphics[scale=.28]{chapters/03_background/img/image_preprocessing.png}
	\caption{Image preprocessing to obtain edge filtered images. The images were taken within the simulation environment Gazebo (\href{http://gazebosim.org/}{link}), and show a space exploration vehicle, for which, with the friendly support of NASA, we generated a Gazebo version (\href{https://github.com/mhubii/gazebo_models}{link}).}
	\label{fig::323_image_preprocessing}
\end{figure}
When having a look at the Sobel kernel $\bm{S}_x$ (equation \ref{eq::323_sobel}), it immediately becomes clear that it approximates the derivative of an image along the horizontal axis. Therefore, at locations of steep change, or simply put, edges, the convolution of the grayscale images with the Sobel kernel results in high values, and thus in the typical appearance of an edge filtered image.
\begin{align}
	\bm{S}_x=
	\begin{pmatrix}
		-1 & 0 & +1 \\
		-2 & 0 & +2 \\
		-1 & 0 & +1
	\end{pmatrix}
	\label{eq::323_sobel}
\end{align}
To understand the block matching algorithm, we first need to figure out the transformation that images undergo for a change in perspective, which is caused by the two different positions of the cameras within the stereo camera pair. 
\begin{figure}[h]
	\centering
	\includegraphics[scale=.28]{chapters/03_background/img/left_disparity_map.png}
	\caption{}
	\label{fig::323_left_disparity_map}
\end{figure}
\begin{figure}[h]
	\centering
	\includegraphics[scale=.28]{chapters/03_background/img/confidence_map.png}
	\caption{}
	\label{fig::323_confidence_map}
\end{figure}
\begin{figure}[h]
	\centering
	\includegraphics[scale=.28]{chapters/03_background/img/weighted_least_squares_disparity.png}
	\caption{}
	\label{fig::323_weighted_least_squares_disparity}
\end{figure}

\cite{egnal2004stereo} left right consistency\\
\cite{min2014fast}   wls\\
\cite{tomasi1998bilateral} bilateral