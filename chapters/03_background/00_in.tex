To generate dynamically balanced walking trajectories for humanoid robots and to let them navigate the environment autonomously, there are several posed challenges that we need to cover. As the logical starting point, in section \ref{sec::31_hw} - Humanoid Walking, we want to address the real time generation of walking trajectories for humanoid robots first, and then think of ways to replace the human user by an artificial agent in the control loop (fig. \ref{fig::3_cl}). The generation of patterns in real time becomes feasible by treating the robot's physics in a simplified way as those of an inverted pendulum (sec. \ref{sec::311_zmp}). The zero moment point of the linear inverted pendulum will therefore serve as the balance criteria for the solution of a sequentially quadratic problem (sec. \ref{sec::312_nmpc}).  Resulting positions and orientations for the center of mass and the feet will then be interpolated (sec. \ref{sec::313_it}) and passed as constraints to the inverse kinematics (sec. \ref{sec::3141_fk}) so to transform them into joint angles that can be sent to the humanoid's motor controllers.
\begin{figure}[h]
	\centering
	\includegraphics[scale=.5]{chapters/03_background/img/control_loop.png}
	\caption{Simplified version of the proposed control loop to navigate the robot with either a human user or an artificial agent.}
	\label{fig::3_cl}
\end{figure}
\\
To close the control loop and to steer the robot towards desired goals, whilst avoiding obstacles, requires some sort of high level command that arises from visual feedback. As discussed in section \ref{sec::2_sota} - State of The Art, there are several ways to achieve this, among them human users. Of particular interest to us are novel methods that evolved from the toolbox of machine learning techniques, as they decrease the computational cost into non existence. Let alone this fact enables us to run them onboard on light weight hardware with low energy usage, which is critical in the domain of humanoid robots. Center to these new methods will be neural nets that we will train on solving the task of autonomous navigation in two different ways. One of which clones the behavior of a human user (sec. \ref{sec::321_bc}), whereas the second presented method (sec. \ref{sec::322_rl}) explores policies and tries to find solutions on its own.
\\\\
As a side note, within the following chapters there will always be made references to the actual implementation of the presented concepts. This shall enable future readers to bridge the gap between theory and application.