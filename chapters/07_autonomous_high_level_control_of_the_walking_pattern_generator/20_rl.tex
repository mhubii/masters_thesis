\FloatBarrier
\section{Reinforcement Learning}
\label{sec::72_rl}
The second approach to autonomous navigation with neural networks is trained via reinforcement learning, especially with proximal policy optimization \cite{schulman2017proximal}, which has recently achieved best results for continuous control tasks. However, since reinforcement learning methods do usually not run in real time, they have to be applied to simulations. The pattern generation library from section \ref{sec::6_pg}, delivers a perfect framework for that, but it requires proximal policy optimization to be implemented in C++ for a seamless integration. Within the scope of this thesis, proximal policy optimization got implemented with the C++ application user interface of PyTorch. It is part of the pattern generation, as shown in figure \ref{fig::72_folder}, where also the Python implementations of the behavioral cloning section can be found. Different network architectures can therein be found in the models header file.
\begin{figure}[h!]
	\begin{forest}
		for tree={
			font=\ttfamily,
			grow'=0,
			child anchor=west,
			parent anchor=south,
			anchor=west,
			calign=first,
			edge path={
				\noexpand\path [draw, \forestoption{edge}]
				(!u.south west) +(7.5pt,0) |- node[fill,inner sep=1.25pt] {} (.child anchor)\forestoption{edge label};
			},
			before typesetting nodes={
				if n=1
				{insert before={[,phantom]}}
				{}
			},
			fit=band,
			before computing xy={l=15pt},
		}
		[\href{https://github.com/mhubii/nmpc_pattern_generator}{\underline{nmpc\_pattern\_generator}}
		[\href{https://github.com/mhubii/nmpc_pattern_generator/tree/master/libs}{\underline{libs}}
		[
		\href{https://github.com/mhubii/nmpc_pattern_generator/tree/master/libs/learning}{\underline{learning}}[\href{https://github.com/mhubii/nmpc_pattern_generator/tree/master/libs/learning/include/learning}{\underline{include/learning}}[models.h][proximal\_policy\_optimization.h]][\href{https://github.com/mhubii/nmpc_pattern_generator/tree/master/libs/learning/python}{\underline{python}}]
		]]]
	\end{forest}
	\caption{The proximal policy optimization algorithm, including the neural network models, are also part of the pattern generation library. The code is freely available on GitHub at the provided \href{https://github.com/mhubii/nmpc_pattern_generator}{\underline{link}}. Install instruction can be found in the appendix \ref{sec::A_si}.}
	\label{fig::72_folder}
\end{figure}
