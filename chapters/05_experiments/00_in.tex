Within the experiments chapter, we will first benchmark the nonlinear model predictive control implementation of ours for purely simulated tasks in section \ref{sec::51_uc}, and then tune hyperparameters for it to run well on Heicub. This will allow us to define a standardized environment for walking experiments in section \ref{sec::512_pt}, to later compare user controlled performance against autonomously controlled performance in section \ref{sec::52_aw}. Though, before we can tackle the idea of behavioral cloning, which got described in section \ref{sec::322_bc}, we need to meat the prerequisites, that is we will calibrate the camera, and tune the depth map parameter extraction in sections \ref{sec::521_cc}, and \ref{sec::522_dp}, respectively. All of the above mentioned steps, will then allow us to collect data and to train a newly developed neural network architecture on it in section \ref{sec::523_da}. Finally, we will compare the humanly controlled robot's balance with the artificially controlled robot's balance in section \ref{sec::524_pt}, and investigate on the reinforcement learning approach for autonomous navigation in section \ref{sec::525_pp}.