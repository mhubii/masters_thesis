In dieser Arbeit erkunden wir die Fähigkeit von neuronalen Netzwerken für die autonome Navigation von humanoiden Robotern. Hierfür wird eine nichtlineare, Modellprädiktive Regelung, die es ermöglicht, stabile Lauftrajektorien in Echtzeit zu erzeugen, implementiert und evaluiert. Darauf folgend werden die neuronalen Netzwerke auf zwei verschiedene Methoden trainiert, nämlich per Verhaltensklonung und per selbstverstärkendem Lernen. Die erste von beiden beruht auf stereo RGB Bildern und es wird demonstriert, dass die Einführung von Tiefenbildern in die Bildverarbeitung genügt, um vielseitige Bewegungsstrategien in vielfältigen dynamischen und statischen Umgebungen zu erlernen. Diese Einfachheit der Lösung wird als passende Ergänzung zur Meidung von Konvexen Hindernissen identifiziert, welche durch Randbedingungen die Lösungen der nichtlinearen Modellprädiktiven Regelung einschränken. Weiterhin wird gezeigt, wie sich das selbstverstärkende Lernen in einer Simulation trainieren lässt und dabei die Entstehung von selbst erlernten Strategien beobachtet, welche sich äquivalent auf den echten Roboter übertragen lassen. Alle Experimente werden an Heicub, einer Variente des iCub, durchgeführt, welcher speziell für Optimalsteuerung in der Fortbewegung am Istituto Italiano di Tecnologiia in Genove entwickelt wurde. Die Auswertung von Balancekriterien zeigt schließlich, dass ein menschlicher Kontrolleur, einem künstlichen Agenten gegenüber, nicht überlegen ist. 